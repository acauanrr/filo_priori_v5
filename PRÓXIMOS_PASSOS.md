# PrÃ³ximos Passos - Full Test

**Data**: 2025-10-16
**Status**: âœ… CorreÃ§Ãµes aplicadas - Pronto para validaÃ§Ã£o

---

## âœ… O Que Foi Feito

### 1. CorreÃ§Ã£o de Paths (Execution_001)
- âœ… Corrigido `output_dir` de `'../results'` â†’ `'results'`
- âœ… Adicionadas validaÃ§Ãµes de salvamento
- âœ… Todos os arquivos agora sÃ£o salvos corretamente

### 2. AnÃ¡lise do Smoke Test (Execution_002)
- âœ… Identificado overfitting severo (val AUPRC 0.83 â†’ test 0.04)
- âœ… Identificado discrimination ruim (0.97x)
- âœ… Identificado APFD per-build inadequado (apenas 16.7% â‰¥ 0.7)

### 3. AplicaÃ§Ã£o de CorreÃ§Ãµes de HiperparÃ¢metros

| ParÃ¢metro | Antes | Depois | Status |
|-----------|-------|--------|--------|
| `pos_weight` | 5.0 | **10.0** | âœ… |
| `label_smoothing` | 0.05 | **0.01** | âœ… |
| `dropout` | 0.1 | **0.2** | âœ… |
| `patience` | 8 | **5** | âœ… |
| `target_positive_fraction` | 0.20 | **0.30** | âœ… |
| `learning_rate` | 5e-4 | **3e-4** | âœ… |
| `weight_decay` | 0.01 | **0.05** | âœ… |

**Backup criado**: `filo_priori/scripts/core/run_experiment_server.py.backup_pre_hyperparams`

---

## ğŸš€ PrÃ³ximos Passos

### OpÃ§Ã£o 1: Validar com Smoke Test (RECOMENDADO)

**Objetivo**: Verificar se as correÃ§Ãµes melhoraram as mÃ©tricas antes de rodar full test (2-6h)

```bash
cd ~/iats/filo_priori_v5

# 1. Rodar smoke test com novos hiperparÃ¢metros (15-30 min)
./run_smoke_test.sh

# 2. Analisar resultados (execution_003)
cat filo_priori/results/execution_003/summary.txt

# 3. Extrair mÃ©tricas chave
python -c "
import json
with open('filo_priori/results/execution_003/metrics.json') as f:
    m = json.load(f)['metrics']
    p = json.load(f)['probability_stats']

print('ğŸ” MÃ‰TRICAS CRÃTICAS:')
print(f\"  Discrimination: {m['discrimination_ratio']:.2f}x (antes: 0.97x)\")
print(f\"  Test AUPRC: {m['auprc']:.4f} (antes: 0.0400)\")
print(f\"  Test Precision: {m['precision']:.4f} (antes: 0.0364)\")
print(f\"  Test Recall: {m['recall']:.4f} (antes: 0.0769)\")
print(f\"  Failures mean prob: {p['failures_mean']:.4f} (antes: 0.1801)\")
print(f\"  Passes mean prob: {p['passes_mean']:.4f} (antes: 0.1860)\")
"

# 4. Verificar APFD per-build
cat filo_priori/results/execution_003/apfd_per_build.csv
```

#### âœ… Checklist de ValidaÃ§Ã£o

Se as correÃ§Ãµes funcionaram, vocÃª deve ver:

- [ ] **Discrimination > 1.5x** (antes: 0.97x)
  - Failures prob > Passes prob
  - Ideal: 2.0x-4.0x

- [ ] **Test AUPRC > 0.15** (antes: 0.04)
  - Mostra que modelo estÃ¡ aprendendo
  - Ideal: 0.20-0.40

- [ ] **Val/Test gap < 50%** (antes: 95%)
  - Overfitting reduzido
  - Ideal: 20-40%

- [ ] **Mean APFD > 0.55** (antes: 0.52)
  - Melhoria pequena mas positiva
  - Ideal: 0.60-0.70

- [ ] **Builds com APFD â‰¥ 0.7 > 20%** (antes: 16.7%)
  - Mais builds com boa performance
  - Ideal: 30-50% no smoke test

#### ğŸ¯ DecisÃ£o

**Se TODOS os checks passarem** â†’ Ir para OpÃ§Ã£o 2 (Full Test)
**Se 3-4 checks passarem** â†’ Ir para OpÃ§Ã£o 2 com expectativas moderadas
**Se â‰¤2 checks passarem** â†’ Ver seÃ§Ã£o "Se Performance NÃ£o Melhorar"

---

### OpÃ§Ã£o 2: Rodar Full Test (ApÃ³s ValidaÃ§Ã£o)

**PrÃ©-requisitos**:
- âœ… Smoke test com correÃ§Ãµes mostrou melhorias
- âœ… Discrimination > 1.5x
- âœ… Test AUPRC > 0.15

**Comando**:
```bash
cd ~/iats/filo_priori_v5

# Verificar conteÃºdo do script
cat run_full_test.sh

# Rodar full test (2-6h GPU, 12-24h CPU)
./run_full_test.sh
```

**Durante a execuÃ§Ã£o**:
```bash
# Monitorar em tempo real (outro terminal)
tail -f filo_priori/results/execution_XXX/full_run.log | grep -E "(Epoch|val_auprc|Best)"

# Ver progresso
ps aux | grep python | grep run_experiment

# GPU usage (se GPU disponÃ­vel)
nvidia-smi -l 5
```

**ApÃ³s conclusÃ£o**:
```bash
# Ver resultado
EXEC_DIR=$(ls -t filo_priori/results/ | grep execution | head -1)
cat filo_priori/results/$EXEC_DIR/summary.txt

# MÃ©tricas detalhadas
cat filo_priori/results/$EXEC_DIR/metrics.json | python -m json.tool

# APFD per-build
head -20 filo_priori/results/$EXEC_DIR/apfd_per_build.csv
```

#### ğŸ¯ Meta do Full Test

```
Target (para considerar sucesso):
  âœ… Mean APFD: â‰¥ 0.70
  âœ… Builds com APFD â‰¥ 0.6: â‰¥ 70%
  âœ… Test AUPRC: â‰¥ 0.20
  âœ… Discrimination: â‰¥ 2.0x

Esperado (baseado em anÃ¡lise):
  ğŸ“Š Mean APFD: 0.65-0.75
  ğŸ“Š Builds â‰¥ 0.7: 50-70%
  ğŸ“Š Test AUPRC: 0.20-0.40
  ğŸ“Š Discrimination: 2.0-4.0x
```

---

### OpÃ§Ã£o 3: Rodar Full Test Direto (NÃ£o Recomendado)

**Se vocÃª quiser pular validaÃ§Ã£o** (nÃ£o recomendado mas possÃ­vel):

```bash
cd ~/iats/filo_priori_v5
./run_full_test.sh
```

**Riscos**:
- Perder 2-6h se correÃ§Ãµes nÃ£o funcionaram
- Sem feedback intermediÃ¡rio
- DifÃ­cil debugar se falhar

---

## ğŸ” Se Performance NÃ£o Melhorar

### DiagnÃ³stico RÃ¡pido

Se apÃ³s smoke test com correÃ§Ãµes vocÃª ainda vÃª:
- âŒ Discrimination < 1.2x
- âŒ Test AUPRC < 0.10
- âŒ Val/Test gap > 80%

**Problema provÃ¡vel**: CorreÃ§Ãµes nÃ£o foram suficientes ou hÃ¡ problema estrutural.

### Plano B

#### 1. Verificar se CalibraÃ§Ã£o EstÃ¡ Ativa

```python
# Verificar cÃ³digo de inferÃªncia
cat filo_priori/utils/inference.py | grep -A 20 "ProbabilityCalibrator"
```

Se calibraÃ§Ã£o NÃƒO estÃ¡ sendo usada no `run_experiment_server.py`, isso pode explicar discrimination ruim.

#### 2. Tentar HiperparÃ¢metros Mais Agressivos

```python
# Editar manualmente run_experiment_server.py:

'pos_weight': 15.0,  # Aumentar ainda mais
'label_smoothing': 0.0,  # Desabilitar completamente
'dropout': 0.3,  # Aumentar mais
'target_positive_fraction': 0.40,  # ForÃ§ar mais exposiÃ§Ã£o
```

#### 3. Simplificar Modelo (Reduzir Overfitting)

```python
# Para smoke test, reduzir complexidade:
'saint': {
    'num_layers': 4,  # Era 6
    'embedding_dim': 96,  # Era 128
    'dropout': 0.3,
}
```

#### 4. Considerar Modelo Mais Simples

Se SAINT continuar com overfitting:
- Testar MLP profundo ao invÃ©s de SAINT
- CÃ³digo jÃ¡ tem MLP em `models/mlp.py`

---

## ğŸ“Š ComparaÃ§Ã£o Esperada

### Execution_002 (Sem CorreÃ§Ãµes)

```
âŒ Discrimination: 0.97x
âŒ Test AUPRC: 0.0400
âŒ Precision: 0.0364
âŒ Recall: 0.0769
âŒ Mean APFD: 0.5154
âŒ Builds â‰¥ 0.7: 16.7%
```

### Execution_003 (Com CorreÃ§Ãµes) - Esperado

```
âœ… Discrimination: 1.5-3.0x (â†‘ 55-210%)
âœ… Test AUPRC: 0.15-0.30 (â†‘ 275-650%)
âœ… Precision: 0.08-0.20 (â†‘ 120-450%)
âœ… Recall: 0.15-0.40 (â†‘ 95-420%)
âœ… Mean APFD: 0.55-0.65 (â†‘ 7-26%)
âœ… Builds â‰¥ 0.7: 25-45% (â†‘ 50-170%)
```

### Full Test (Com Mais Dados) - Esperado

```
ğŸ¯ Discrimination: 2.0-4.0x
ğŸ¯ Test AUPRC: 0.20-0.40
ğŸ¯ Precision: 0.12-0.30
ğŸ¯ Recall: 0.30-0.60
ğŸ¯ Mean APFD: 0.65-0.75
ğŸ¯ Builds â‰¥ 0.7: 50-70%
```

---

## ğŸ› ï¸ Comandos Ãšteis

### Reverter CorreÃ§Ãµes (Se NecessÃ¡rio)

```bash
cd ~/iats/filo_priori_v5/filo_priori
cp scripts/core/run_experiment_server.py.backup_pre_hyperparams scripts/core/run_experiment_server.py
```

### Comparar ExecuÃ§Ãµes

```bash
# Comparar mÃ©tricas entre execution_002 e execution_003
python -c "
import json

with open('results/execution_002/metrics.json') as f:
    m2 = json.load(f)['metrics']
with open('results/execution_003/metrics.json') as f:
    m3 = json.load(f)['metrics']

print('COMPARAÃ‡ÃƒO: Execution_002 vs Execution_003')
print('='*60)
for key in ['discrimination_ratio', 'auprc', 'precision', 'recall']:
    v2, v3 = m2[key], m3[key]
    delta = ((v3 - v2) / v2 * 100) if v2 != 0 else float('inf')
    status = 'âœ…' if v3 > v2 else 'âŒ'
    print(f'{status} {key:20s}: {v2:.4f} â†’ {v3:.4f} ({delta:+.1f}%)')
"
```

### Limpar ExecuÃ§Ãµes Antigas

```bash
# Se precisar de espaÃ§o
cd ~/iats/filo_priori_v5/filo_priori/results

# Listar tamanhos
du -sh execution_*

# Manter apenas logs e mÃ©tricas, deletar modelos pesados
for dir in execution_0*; do
    echo "Cleaning $dir..."
    # rm -f $dir/best_model.pth  # Libera 20-30MB por execuÃ§Ã£o
done
```

---

## ğŸ“ Arquivos de ReferÃªncia

### DocumentaÃ§Ã£o
- `RESUMO_EXECUTIVO.md` - Resumo visual da anÃ¡lise
- `ANÃLISE_SMOKE_TEST_EXECUTION_002.md` - AnÃ¡lise tÃ©cnica completa
- `CORREÃ‡Ã•ES_APLICADAS.md` - CorreÃ§Ãµes de paths anteriores
- `PRÃ“XIMOS_PASSOS.md` - Este arquivo

### Resultados
- `filo_priori/results/execution_002/` - Smoke test SEM correÃ§Ãµes
- `filo_priori/results/execution_003/` - Smoke test COM correÃ§Ãµes (apÃ³s vocÃª rodar)
- `filo_priori/results/execution_XXX/` - Full test (apÃ³s vocÃª rodar)

### CÃ³digo
- `filo_priori/scripts/core/run_experiment_server.py` - Script principal (MODIFICADO)
- `filo_priori/scripts/core/run_experiment_server.py.backup_pre_hyperparams` - Backup

### Scripts de Teste
- `run_smoke_test.sh` - Smoke test (15-30 min)
- `run_full_test.sh` - Full test (2-6h)
- `test_path_fix.sh` - Validar paths (jÃ¡ passou âœ…)

---

## ğŸ¯ RecomendaÃ§Ã£o Final

### Path CrÃ­tico (Recomendado)

```
1. Rodar smoke test (15-30 min) âœ…
   â””â”€> ./run_smoke_test.sh

2. Validar mÃ©tricas (5 min) âœ…
   â””â”€> Ver checklist acima

3. Se OK: Rodar full test (2-6h) âœ…
   â””â”€> ./run_full_test.sh

4. Analisar resultados finais (10 min) âœ…
   â””â”€> Ver summary.txt e metrics.json
```

### Estimativa de Tempo Total

- **Com validaÃ§Ã£o**: 3-7h (15-30min smoke + 2-6h full)
- **Sem validaÃ§Ã£o**: 2-6h (full direto, arriscado)

### Chance de Sucesso

- **Com correÃ§Ãµes aplicadas**: 60-70%
- **Sem correÃ§Ãµes**: 10-20%

---

**BOA SORTE!** ğŸš€

Qualquer problema, consulte a documentaÃ§Ã£o detalhada em `ANÃLISE_SMOKE_TEST_EXECUTION_002.md`.
