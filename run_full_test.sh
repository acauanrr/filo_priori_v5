#!/bin/bash
# Script helper para executar full test do Filo-Priori V5 (BGE + SAINT)
# Uso: ./run_full_test.sh

echo "ðŸš€ Executando Filo-Priori V5 - Full Test (BGE + SAINT)"
echo "========================================================"
echo "ðŸ“Œ Modelo: BGE-large-en-v1.5 (1024D) + SAINT Transformer"
echo "ðŸ“Œ Dataset completo: ~1.7GB train + ~581MB test"
echo "ðŸ“Œ SAINT: 6 layers, 8 heads, intersample attention"
echo "ðŸ“Œ Treinamento: ~30 epochs com early stopping"
echo "ðŸ“Œ OtimizaÃ§Ãµes: batch_size=256 para BGE, weights_only=False para PyTorch 2.6+"
echo "â±ï¸  Tempo estimado:"
echo "   - Embeddings: ~5-10 min (GPU) ou ~30-60 min (CPU)"
echo "   - Treinamento: ~45-90 min (GPU) ou ~2-4 horas (CPU)"
echo "   - Total: ~1-2 horas (GPU) ou ~3-5 horas (CPU)"
echo ""

cd filo_priori

# Auto-detect device (prefer CUDA if available)
if command -v nvidia-smi &> /dev/null; then
    GPU_AVAILABLE=$(nvidia-smi --query-gpu=name --format=csv,noheader 2>/dev/null | wc -l)
    if [ "$GPU_AVAILABLE" -gt 0 ]; then
        GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)
        GPU_MEMORY=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
        echo "ðŸŽ® GPU detectada: $GPU_NAME ($GPU_MEMORY MB)"
        echo "ðŸ”§ Usando CUDA para aceleraÃ§Ã£o"
        DEVICE="cuda"
    else
        echo "ðŸ’» nvidia-smi encontrado mas sem GPU disponÃ­vel, usando CPU"
        DEVICE="cpu"
    fi
else
    echo "ðŸ’» GPU nÃ£o detectada, usando CPU"
    DEVICE="cpu"
fi

echo ""
echo "ðŸ”§ Iniciando pipeline completo..."
echo "âš ï¸  ATENÃ‡ÃƒO: Isso pode demorar vÃ¡rias horas. Considere usar 'nohup' ou 'screen' para sessÃµes longas."
echo ""

# Start timestamp
START_TIME=$(date +%s)

python scripts/core/run_experiment_server.py --full-test --device $DEVICE

EXIT_CODE=$?

# End timestamp
END_TIME=$(date +%s)
ELAPSED=$((END_TIME - START_TIME))
HOURS=$((ELAPSED / 3600))
MINUTES=$(((ELAPSED % 3600) / 60))
SECONDS=$((ELAPSED % 60))

echo ""
echo "â±ï¸  Tempo total de execuÃ§Ã£o: ${HOURS}h ${MINUTES}m ${SECONDS}s"
echo ""

if [ $EXIT_CODE -eq 0 ]; then
    # Find last execution directory
    LAST_EXEC=$(ls -t results/ | grep "execution_" | head -1)
    echo "âœ… Full test concluÃ­do com sucesso!"
    echo "ðŸ“Š Resultados salvos em: filo_priori/results/$LAST_EXEC/"
    echo ""
    echo "ðŸ“ Arquivos principais:"
    echo "   - metrics.json (mÃ©tricas completas)"
    echo "   - best_model.pth (modelo SAINT treinado - checkpoint)"
    echo "   - training_history.json (histÃ³rico de treinamento por Ã©poca)"
    echo "   - prioritized_hybrid.csv (testes priorizados)"
    echo "   - apfd_per_build.csv (APFD por build)"
    echo "   - summary.txt (resumo do experimento)"
    echo ""
    echo "ðŸŽ¯ MÃ©tricas esperadas:"
    echo "   - APFD â‰¥ 0.70 (target)"
    echo "   - AUPRC â‰¥ 0.20"
    echo "   - Precision â‰¥ 0.15"
    echo "   - Recall â‰¥ 0.50"
    echo ""
    echo "ðŸ“ˆ Para ver o resumo completo:"
    echo "   cat filo_priori/results/$LAST_EXEC/summary.txt"
    echo ""
    echo "ðŸ“Š Para ver mÃ©tricas APFD:"
    echo "   cat filo_priori/results/$LAST_EXEC/metrics.json | grep -A 20 apfd_per_build"
else
    echo "âŒ Full test falhou com cÃ³digo de erro: $EXIT_CODE"
    echo ""
    echo "ðŸ’¡ Troubleshooting:"
    echo "   1. Verifique se o venv estÃ¡ ativado: source venv/bin/activate"
    echo "   2. Verifique dependÃªncias: pip install -r requirements.txt"
    echo "   3. Se erro de GPU/memÃ³ria, force CPU: cd filo_priori && python scripts/core/run_experiment_server.py --full-test --device cpu"
    echo "   4. Se CUDA OOM, reduza batch_size em filo_priori/scripts/core/run_experiment_server.py (linha 96: batch_size: 16 -> 8)"
    echo "   5. Verifique logs em filo_priori/results/execution_XXX/ (se criado)"
    echo ""
    echo "ðŸ“‹ Para execuÃ§Ã£o longa em servidor, use:"
    echo "   nohup ./run_full_test.sh > full_test.log 2>&1 &"
    echo "   tail -f full_test.log  # para monitorar"
fi

exit $EXIT_CODE
