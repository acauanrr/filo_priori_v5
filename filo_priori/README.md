# Filo-Priori V5

Solu√ß√£o melhorada para prioriza√ß√£o de testes usando:
- **Extra√ß√£o estruturada** de commits (issues, APIs, erros, etc.)
- **SBERT multil√≠ngue** (384D ‚Üí 128D) para embeddings sem√¢nticos
- **FT-Transformer** ou MLP profundo com balanceamento classe-ciente
- **Estratifica√ß√£o** por Build_ID e otimiza√ß√£o de limiar

## üìÅ Estrutura

```
filo_priori_v5/
‚îú‚îÄ‚îÄ data_processing/
‚îÇ   ‚îú‚îÄ‚îÄ 01_parse_commit.py       # Extra√ß√£o estruturada de commits
‚îÇ   ‚îú‚îÄ‚îÄ 02_build_text_semantic.py # Constru√ß√£o de text_semantic
‚îÇ   ‚îî‚îÄ‚îÄ 03_embed_sbert.py         # Embeddings SBERT + PCA + Scaler
‚îú‚îÄ‚îÄ models/                       # (FT-Transformer - implementar se necess√°rio)
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml               # Configura√ß√£o centralizada
‚îî‚îÄ‚îÄ artifacts/                    # Outputs (embeddings, models, reports)
```

## üöÄ Como Usar

### Execu√ß√£o R√°pida (Smoke Test)
```bash
cd /home/acauan/ufam/iats/sprint_07/filo_priori_v4/filo_priori

python scripts/core/run_experiment_server.py \
    --smoke-train 100 \
    --smoke-test 50 \
    --smoke-epochs 20
```

### Execu√ß√£o Completa (Full Test)
```bash
cd /home/acauan/ufam/iats/sprint_07/filo_priori_v4/filo_priori
python scripts/core/run_experiment_server.py --full-test
```

### Comparar Experimentos
```bash
# Ver compara√ß√£o no terminal
python scripts/compare_executions.py

# Exportar para CSV
python scripts/compare_executions.py --export comparison.csv
```

## üìÅ Sistema de Execu√ß√µes

Cada execu√ß√£o cria automaticamente uma pasta `results/execution_XXX/` contendo:

- **metrics.json** - M√©tricas completas (APFD, AUPRC, discrimination, etc.)
- **config.json** - Configura√ß√£o usada no experimento
- **best_model.pt** - Checkpoint do melhor modelo
- **prioritized_hybrid.csv** - Predi√ß√µes com ranks
- **training_history.csv** - Hist√≥rico de treinamento (f√°cil plotar)
- **summary.txt** - Resumo leg√≠vel
- **feature_builder.pkl** - Artefatos de feature engineering
- **embedder/** - Artefatos do SBERT (PCA, scaler)

Isso permite:
- ‚úÖ Comparar experimentos facilmente
- ‚úÖ Reproduzir resultados exatos
- ‚úÖ Versionar automaticamente cada execu√ß√£o
- ‚úÖ N√£o sobrescrever resultados anteriores

## üîÑ Pipeline Detalhado

### 1. Parse de Commits
```bash
python data_processing/01_parse_commit.py ../datasets/train.csv ../artifacts/train_parsed.csv
```

**Sa√≠da**: Adiciona colunas `commit_issue_ids`, `commit_apis`, `commit_errors`, `commit_text`, etc.

### 2. Constru√ß√£o de text_semantic
```bash
python data_processing/02_build_text_semantic.py ../artifacts/train_parsed.csv ../artifacts/train_semantic.csv
```

**Sa√≠da**: Adiciona `text_semantic` (TE_Summary + TC_Steps + commit_text) e `label_binary` (0/1).

### 3. Gera√ß√£o de Embeddings
```bash
python data_processing/03_embed_sbert.py ../artifacts/train_semantic.csv 128 ../artifacts/embeddings/
```

**Sa√≠da**:
- `embeddings_train.npy` (padronizado)
- `pca.pkl`, `scaler.pkl` (artefatos para valida√ß√£o/teste)

### 4. Treino (implementar depois)
```bash
# Usar embeddings + features tabulares no FT-Transformer
# Com balanced sampler, class weights, e PR-AUC
```

## üìä Melhorias vs V4

| Aspecto | V4 | V5 |
|---------|----|----|
| Features de commit | ‚ùå Brutas | ‚úÖ Estruturadas (APIs, erros, m√≥dulos) |
| Embeddings | ‚ùå 768D sem normaliza√ß√£o | ‚úÖ 384D‚Üí128D + PCA + Scaler |
| Modelo | MLP 2 camadas | MLP profundo ou FT-Transformer |
| Balanceamento | Sampler simples | **Classe-ciente** + Focal Loss opcional |
| Diversidade | Penaliza igualmente | Deduplica√ß√£o por classe |
| Split | Aleat√≥rio | GroupKFold por Build_ID |

## üéØ Pr√≥ximos Passos

1. **Implementar m√≥dulo de treino** (`04_train_ftt.py` ou usar v4 adaptado)
2. **Testar com smoke test** (100 builds)
3. **Adicionar features temporais enriquecidas** (16D em vez de 4D)
4. **Ajustar pesos hybrid**: `0.9√óprob + 0.1√ódiv`

## üì¶ Depend√™ncias

```bash
pip install pandas numpy scikit-learn sentence-transformers torch
# Para FT-Transformer: pip install rtdl (Research Tabular Deep Learning)
```

## üìù Notas

- **text_semantic** combina informa√ß√£o de 3 fontes com tags estruturadas
- **commit_text** prioriza: Errors > Actions > APIs > Modules > Flags
- **Labels amb√≠guos** (Blocked, Pending) s√£o removidos automaticamente
- **Imbalance**: Mant√©m ~3% taxa de falha, usar sampler 1:3 nos batches
- **PCA 128D** preserva >95% da vari√¢ncia com 1/3 das dimens√µes

---

**Autor**: Filo-Priori V5 Team
**Data**: 2025-10-15
