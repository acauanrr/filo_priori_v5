# ‚úÖ Filo-Priori V5 - Checklist de Valida√ß√£o (BGE + SAINT)

**Data da Refatora√ß√£o**: 2025-10-16
**Objetivo**: Substituir SBERT ‚Üí BGE e TabPFN ‚Üí SAINT Transformer

---

## üéØ Mudan√ßas Implementadas

### ‚úÖ 1. Embeddings de Texto (BGE)
- [x] **J√° implementado** - BGE-large-en-v1.5 em `filo_priori/data_processing/03_embed_sbert.py`
- [x] PCA removido - embeddings 1024D usados diretamente
- [x] StandardScaler mantido para normaliza√ß√£o

**Arquivo**: `filo_priori/data_processing/03_embed_sbert.py:29`

---

### ‚úÖ 2. Modelo SAINT Transformer (NOVO)
- [x] Implementa√ß√£o completa em `filo_priori/models/saint.py`
- [x] Self-attention (aten√ß√£o intra-amostra)
- [x] **Intersample attention** (aten√ß√£o entre amostras - inova√ß√£o do SAINT)
- [x] Arquitetura: 6 layers, 8 heads, embedding_dim=128
- [x] Dropout=0.1 para regulariza√ß√£o

**Componentes**:
- `EmbeddingLayer`: Projeta features cont√≠nuas (1028D) para embeddings (128D)
- `MultiHeadSelfAttention`: Aten√ß√£o padr√£o dentro de cada amostra
- `IntersampleAttention`: Aten√ß√£o entre diferentes amostras no batch
- `SAINTBlock`: Combina ambas as aten√ß√µes + MLP
- `SAINT`: Modelo completo com pooling e classifica√ß√£o

**Arquivo**: `filo_priori/models/saint.py` (489 linhas)

---

### ‚úÖ 3. Treinamento SAINT (NOVO)
- [x] Training loop completo em `filo_priori/utils/saint_trainer.py`
- [x] Early stopping baseado em `val_auprc` (ideal para dados desbalanceados)
- [x] Cosine LR schedule com warmup (3 epochs warmup)
- [x] Gradient clipping (max_norm=1.0)
- [x] Label smoothing (0.05)
- [x] Class imbalance handling:
  - WeightedRandomSampler (target 20% positivos)
  - pos_weight=5.0 no BCE loss

**Arquivo**: `filo_priori/utils/saint_trainer.py` (467 linhas)

---

### ‚úÖ 4. Pipeline Atualizado
- [x] `run_experiment_server.py` completamente refatorado
- [x] Removido todo c√≥digo TabPFN
- [x] Adicionado treinamento PyTorch com DataLoaders
- [x] Mant√©m feature engineering (1028D = 1024 BGE + 4 temporal)
- [x] Checkpointing do melhor modelo (baseado em val_auprc)

**Arquivo**: `filo_priori/scripts/core/run_experiment_server.py` (677 linhas)

---

### ‚úÖ 5. Configura√ß√£o
- [x] `config.yaml` atualizado com se√ß√£o SAINT
- [x] Removida se√ß√£o TabPFN
- [x] Adicionados par√¢metros de treinamento completos
- [x] Valores conservadores para estabilidade

**Arquivo**: `config.yaml`

---

### ‚úÖ 6. Depend√™ncias
- [x] `requirements.txt` atualizado
- [x] Removido: `tabpfn>=0.1.9`
- [x] Mantido: PyTorch, sentence-transformers, sklearn
- [x] N√£o h√° novas depend√™ncias necess√°rias

**Arquivo**: `requirements.txt`

---

### ‚úÖ 7. Scripts de Execu√ß√£o
- [x] `run_full_test.sh` atualizado para SAINT
- [x] `run_smoke_test.sh` atualizado para SAINT
- [x] Auto-detec√ß√£o de GPU/CPU
- [x] Mensagens de output corrigidas (best_model.pth, n√£o .pkl)
- [x] Permiss√µes de execu√ß√£o configuradas (`chmod +x`)

**Arquivos**:
- `run_full_test.sh` (60 linhas)
- `run_smoke_test.sh` (54 linhas)

---

## üöÄ Valida√ß√£o para Execu√ß√£o no Servidor

### Pr√©-requisitos
```bash
# 1. Verificar PyTorch instalado
python -c "import torch; print(f'PyTorch {torch.__version__}')"

# 2. Verificar sentence-transformers
python -c "import sentence_transformers; print('‚úì sentence-transformers OK')"

# 3. Verificar estrutura de arquivos
ls filo_priori/models/saint.py
ls filo_priori/utils/saint_trainer.py
ls filo_priori/scripts/core/run_experiment_server.py

# 4. Verificar datasets
ls datasets/train.csv datasets/test_full.csv
```

### Execu√ß√£o no Servidor

#### Op√ß√£o 1: Smoke Test (Valida√ß√£o R√°pida)
```bash
./run_smoke_test.sh
```
**Tempo esperado**: ~10-20 minutos
**Builds**: 100 treino, 50 teste
**Objetivo**: Validar que o pipeline funciona end-to-end

#### Op√ß√£o 2: Full Test (Produ√ß√£o)
```bash
./run_full_test.sh
```
**Tempo esperado**:
- GPU: ~30-60 minutos
- CPU: ~2-4 horas

**Dataset completo**: ~1.7GB treino + ~581MB teste

#### Op√ß√£o 3: Manual (Controle Total)
```bash
cd filo_priori

# Com GPU
python scripts/core/run_experiment_server.py --full-test --device cuda

# For√ßar CPU
python scripts/core/run_experiment_server.py --full-test --device cpu

# Custom smoke test
python scripts/core/run_experiment_server.py \
    --smoke-train 50 \
    --smoke-test 25 \
    --device cuda
```

---

## üìä Outputs Esperados

Ap√≥s execu√ß√£o bem-sucedida, voc√™ encontrar√° em `filo_priori/results/execution_XXX/`:

```
execution_001/
‚îú‚îÄ‚îÄ metrics.json              # M√©tricas completas (APFD, AUPRC, etc.)
‚îú‚îÄ‚îÄ config.json               # Configura√ß√£o do experimento
‚îú‚îÄ‚îÄ best_model.pth            # Checkpoint do SAINT (melhor √©poca)
‚îú‚îÄ‚îÄ training_history.json     # M√©tricas por √©poca
‚îú‚îÄ‚îÄ prioritized_hybrid.csv    # Testes ranqueados por probabilidade
‚îú‚îÄ‚îÄ apfd_per_build.csv        # APFD calculado por build
‚îú‚îÄ‚îÄ summary.txt               # Resumo textual do experimento
‚îú‚îÄ‚îÄ feature_builder.pkl       # Feature engineering artifacts
‚îî‚îÄ‚îÄ embedder/
    ‚îî‚îÄ‚îÄ scaler.pkl            # StandardScaler para BGE embeddings
```

### Estrutura do `metrics.json`
```json
{
  "metadata": {
    "model_type": "SAINT",
    "embedding_model": "BAAI/bge-large-en-v1.5",
    "embedding_dim": 1024,
    "model_params": 2000000,  // ~2M par√¢metros
    "device": "cuda",
    "timestamp": "2025-10-16T..."
  },
  "metrics": {
    "apfd": 0.70,      // Target ‚â• 0.70
    "apfdc": 0.72,
    "auprc": 0.25,     // Target ‚â• 0.20
    "precision": 0.18, // Target ‚â• 0.15
    "recall": 0.65,    // Target ‚â• 0.50
    "f1": 0.28,
    "accuracy": 0.92
  },
  "training": {
    "best_epoch": 12,
    "best_metric": 0.0245,  // val_auprc
    "monitor_metric": "val_auprc",
    "history": { ... }
  }
}
```

---

## ‚ö†Ô∏è Poss√≠veis Problemas e Solu√ß√µes

### 1. Erro: `ModuleNotFoundError: No module named 'torch'`
**Solu√ß√£o**: Instalar depend√™ncias
```bash
pip install -r requirements.txt
```

### 2. Erro: CUDA out of memory
**Solu√ß√£o 1**: Reduzir batch_size em `config.yaml`
```yaml
training:
  batch_size: 8  # Reduzir de 16 para 8
```

**Solu√ß√£o 2**: For√ßar CPU
```bash
python scripts/core/run_experiment_server.py --full-test --device cpu
```

### 3. Erro: `FileNotFoundError: datasets/train.csv`
**Solu√ß√£o**: Verificar caminho relativo
```bash
pwd  # Deve estar em filo_priori_v5/
ls datasets/  # Deve listar train.csv e test_full.csv
```

### 4. Treinamento muito lento em CPU
**Esperado**: CPU √© ~10-20x mais lento que GPU para SAINT
- Smoke test: ~10-20 min (CPU)
- Full test: ~2-4 horas (CPU)

**Alternativa**: Usar servidor com GPU ou reduzir smoke test:
```bash
python filo_priori/scripts/core/run_experiment_server.py \
    --smoke-train 20 --smoke-test 10 --device cpu
```

---

## ‚úÖ Checklist Final de Valida√ß√£o

Antes de rodar no servidor, verifique:

- [ ] PyTorch instalado e funcionando
- [ ] sentence-transformers instalado
- [ ] Datasets presentes em `datasets/`
- [ ] Arquivos SAINT criados:
  - [ ] `filo_priori/models/saint.py`
  - [ ] `filo_priori/models/__init__.py`
  - [ ] `filo_priori/utils/saint_trainer.py`
- [ ] Scripts de execu√ß√£o atualizados:
  - [ ] `run_full_test.sh` (menciona SAINT, n√£o TabPFN)
  - [ ] `run_smoke_test.sh` (menciona SAINT, n√£o TabPFN)
- [ ] Permiss√µes de execu√ß√£o: `ls -l run_*.sh` mostra `-rwxr-xr-x`
- [ ] Nenhum c√≥digo TabPFN restante no pipeline

---

## üìù Notas Adicionais

1. **Tempo de Treinamento**: SAINT requer treinamento real (diferente de TabPFN que era pr√©-treinado), ent√£o espere:
   - Smoke test: ~10-20 minutos (CPU) ou ~2-5 minutos (GPU)
   - Full test: ~2-4 horas (CPU) ou ~30-60 minutos (GPU)

2. **Early Stopping**: O treinamento pode parar antes de 30 √©pocas se n√£o houver melhoria em `val_auprc` por 8 √©pocas consecutivas.

3. **Melhor √âpoca**: O modelo salvo (`best_model.pth`) √© da √©poca com melhor `val_auprc`, n√£o necessariamente a √∫ltima √©poca.

4. **Intersample Attention**: Esta √© a principal inova√ß√£o do SAINT. Se voc√™ quiser desabilitar para compara√ß√£o:
   ```yaml
   # Em config.yaml
   saint:
     use_intersample: false  # Vira transformer padr√£o
   ```

5. **Monitoramento**: Para acompanhar progresso em tempo real:
   ```bash
   tail -f filo_priori/results/execution_XXX/*.log  # Se houver logs
   # Ou apenas observe os prints no terminal
   ```

---

## üéØ Crit√©rios de Sucesso

O experimento ser√° considerado bem-sucedido se:

1. ‚úÖ Pipeline executa sem erros do in√≠cio ao fim
2. ‚úÖ Gera todos os arquivos de output esperados
3. ‚úÖ APFD ‚â• 0.70 (objetivo principal)
4. ‚úÖ AUPRC ‚â• 0.20
5. ‚úÖ Precision ‚â• 0.15
6. ‚úÖ Recall ‚â• 0.50

---

**√öltima atualiza√ß√£o**: 2025-10-16
**Autor**: Claude Code Agent
**Vers√£o**: Filo-Priori V5 (BGE + SAINT)
