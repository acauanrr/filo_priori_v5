# RelatÃ³rio de AnÃ¡lise - Execution 005 (Full Test)

**Data da ExecuÃ§Ã£o**: 2025-10-15 20:16
**Tipo**: Full Test (dataset completo)
**Device**: CUDA
**Status**: âœ… ExecuÃ§Ã£o completada com sucesso

---

## ğŸ“Š SumÃ¡rio Executivo

### Resultado Geral: âš ï¸ **ABAIXO DO TARGET**

O modelo completou o treinamento com sucesso, mas as mÃ©tricas de teste ficaram **significativamente abaixo dos targets estabelecidos**:

| MÃ©trica | Resultado | Target | Status |
|---------|-----------|--------|--------|
| **APFD** | 0.5733 | â‰¥ 0.70 | âŒ -18% |
| **AUPRC** | 0.0483 | â‰¥ 0.20 | âŒ -76% |
| **Precision** | 0.0702 | â‰¥ 0.15 | âŒ -53% |
| **Recall** | 0.1212 | â‰¥ 0.50 | âŒ -76% |
| **Discrimination** | 1.84x | â‰¥ 2.0x | âŒ -8% |

**ConclusÃ£o**: O modelo apresenta **overfitting severo** - excelente performance em treino/validaÃ§Ã£o, mas generalizaÃ§Ã£o muito fraca para o test set.

---

## ğŸ“ˆ Dataset

### ComposiÃ§Ã£o

```
TRAIN SET:
  - Total: 63,532 samples
  - Failures: 1,654 (2.60%)
  - Passes: 61,878 (97.40%)
  - Imbalance ratio: 37.4:1

TEST SET:
  - Total: 28,859 samples
  - Failures: 924 (3.20%)
  - Passes: 27,935 (96.80%)
  - Imbalance ratio: 30.2:1
```

**ObservaÃ§Ã£o CrÃ­tica**: A taxa de falha no test set (3.20%) Ã© **23% maior** que no train set (2.60%), indicando que o test set Ã© mais desafiador.

---

## ğŸ¯ MÃ©tricas Detalhadas

### 1. APFD (Average Percentage of Faults Detected)

**Resultado**: 0.5733 (Target: â‰¥ 0.70)

**AnÃ¡lise**:
- APFD de 0.57 significa que, em mÃ©dia, as falhas sÃ£o detectadas apÃ³s executar ~43% dos testes
- **Random baseline** seria ~0.50
- Ganho sobre random: apenas **7.3%**
- **InterpretaÃ§Ã£o**: O modelo estÃ¡ apenas marginalmente melhor que ordenaÃ§Ã£o aleatÃ³ria

**DistribuiÃ§Ã£o de Falhas por Percentil**:
```
Top  1% (288 testes):    40/924 falhas (4.3%)  â† Muito baixo
Top  5% (1,442 testes):  104/924 falhas (11.3%) â† Abaixo do esperado
Top 10% (2,885 testes):  152/924 falhas (16.5%) â† Fraco
Top 25% (7,214 testes):  318/924 falhas (34.4%) â† RazoÃ¡vel
Top 50% (14,429 testes): 546/924 falhas (59.1%) â† Ligeiramente acima de 50%
```

**Problema**: Para APFD â‰¥ 0.70, esperarÃ­amos ~60-70% das falhas nos primeiros 25% dos testes. Obtivemos apenas 34.4%.

### 2. AUPRC (Area Under Precision-Recall Curve)

**Resultado**: 0.0483 (Target: â‰¥ 0.20)

**AnÃ¡lise**:
- AUPRC de 0.048 Ã© **extremamente baixo**
- Baseline (proporÃ§Ã£o de falhas): 0.032
- Ganho sobre baseline: apenas **51%**
- **InterpretaÃ§Ã£o**: O modelo tem pouquÃ­ssima capacidade de distinguir falhas de passes

**ComparaÃ§Ã£o com ValidaÃ§Ã£o**:
```
Val AUPRC:  0.6619 (excelente)
Test AUPRC: 0.0483 (terrÃ­vel)
Gap:        0.6136 (92.7% de degradaÃ§Ã£o!)
```

**DiagnÃ³stico**: **Overfitting severo** - o modelo memorizou padrÃµes do train/val set que nÃ£o generalizam.

### 3. Precision & Recall

**Resultados**:
- **Precision**: 0.0702 (7.0%) - De cada 100 testes preditos como falha, apenas 7 realmente falham
- **Recall**: 0.1212 (12.1%) - De cada 100 falhas reais, o modelo detecta apenas 12
- **F1**: 0.0889

**AnÃ¡lise**:
- Precision baixa â†’ Muitos **falsos positivos** (passa predito como falha)
- Recall baixo â†’ Muitos **falsos negativos** (falha predita como passa)
- O modelo estÃ¡ errando em **ambas** as direÃ§Ãµes

**Threshold de 0.5**:
```
PrediÃ§Ãµes positivas: ~3,800 (estimado)
Verdadeiros positivos: 112 (12.1% de 924)
Falsos positivos: ~3,688
```

### 4. Discrimination Ratio

**Resultado**: 1.84x (Target: â‰¥ 2.0x)

**AnÃ¡lise**:
```
Failures mean probability: 0.1384
Passes mean probability:   0.0753
Ratio: 1.84x
```

**InterpretaÃ§Ã£o**:
- O modelo atribui probabilidades apenas **84% maiores** para falhas vs passes
- Target seria 2x (100% maior)
- **DiscriminaÃ§Ã£o fraca** - distribuiÃ§Ãµes de probabilidade muito sobrepostas

**DistribuiÃ§Ã£o de Probabilidades**:
```
FAILURES:
  Mean: 0.1384, Std: 0.2880, Median: 0.0207
  Min: 0.0014, Max: 0.9986

PASSES:
  Mean: 0.0753, Std: 0.1930, Median: 0.0189
  Min: 0.0009, Max: 0.9998
```

**Problema**: Mediana de falhas (0.0207) Ã© quase igual Ã  mediana de passes (0.0189) - modelo nÃ£o estÃ¡ confiante.

---

## ğŸ§  AnÃ¡lise de Treinamento

### Training Progression

```
Epochs executados: 30/30 (sem early stopping)
Best epoch: 30 (Ãºltimo)
Device: CUDA
Training time: ~1.5 horas (estimado)
```

### MÃ©tricas Finais (Epoch 30)

**TRAIN SET**:
```
Loss:      0.2306
Precision: 0.9004 (90.0%)
Recall:    0.9926 (99.3%)
F1:        0.9443
AUPRC:     0.9823
```

**VALIDATION SET**:
```
Loss:      0.3222
Precision: 0.3267 (32.7%)
Recall:    0.7903 (79.0%)
F1:        0.4623
AUPRC:     0.6619
```

**TEST SET**:
```
Loss:      0.7871
Precision: 0.0702 (7.0%)
Recall:    0.1212 (12.1%)
F1:        0.0889
AUPRC:     0.0483
```

### DiagnÃ³stico de Overfitting

| ComparaÃ§Ã£o | Gap | InterpretaÃ§Ã£o |
|------------|-----|---------------|
| Train AUPRC â†’ Val AUPRC | 0.9823 â†’ 0.6619 | -32.6% (overfitting moderado) |
| Val AUPRC â†’ Test AUPRC | 0.6619 â†’ 0.0483 | **-92.7% (colapso total)** |
| Train Recall â†’ Test Recall | 0.9926 â†’ 0.1212 | **-87.8% (colapso)** |

**ConclusÃ£o**: O modelo nÃ£o estÃ¡ apenas overfittando - hÃ¡ uma **incompatibilidade de distribuiÃ§Ã£o** entre val e test sets.

### Early Stopping

**Problema**: Early stopping **NÃƒO ativou** (patience=15 epochs)
- Melhor val_auprc: Epoch 30 (0.6619)
- Val_auprc continuou melhorando atÃ© o final
- **Isso sugere**: O modelo ainda estava aprendendo padrÃµes do val set (overfitting)

**RecomendaÃ§Ã£o**: Patience deveria ter sido **mais restritivo** (ex: patience=5)

---

## ğŸ” AnÃ¡lise de PrediÃ§Ãµes

### Top 20 Testes Mais Priorizados

**Resultado**: 0/20 sÃ£o falhas (0%)

**ObservaÃ§Ã£o crÃ­tica**: Os 20 testes com maior probabilidade sÃ£o **TODOS passes**.

Exemplos:
```
Rank  TC_Key       Result  Probability
1     MCA-3035541  Pass    0.9998
2     MCA-3035541  Pass    0.9998
3     MCA-3035541  Pass    0.9997
...
20    MCA-847869   Pass    0.9989
```

**Problema**: O modelo estÃ¡ **superconfiante em passes**, nÃ£o em falhas.

### AnÃ¡lise de Falhas

**Falhas melhor rankeadas** (sucesso do modelo):
```
Rank  TC_Key       Probability
23    MCA-3061393  0.9986  â† Excelente!
24    MCA-3061393  0.9986
51    MCA-2947933  0.9979
52    MCA-2947933  0.9979
```

**Apenas 96 falhas (10.4%)** tÃªm probabilidade > 0.7 (alta confianÃ§a)

**Falhas pior rankeadas** (fracasso do modelo):
```
Rank   TC_Key       Probability
28847  MCA-3035541  0.0014  â† Mesmo TC do top 1!
28846  MCA-3035541  0.0014
28713  MCA-1874     0.0084
```

**748 falhas (81%)** tÃªm probabilidade < 0.05 (modelo nÃ£o detectou)

### DistribuiÃ§Ã£o de Falhas por Probabilidade

```
Bin         Count    % de Falhas
0-5%        748      81.0%    â† Maioria nÃ£o detectada
5-10%       20       2.2%
10-20%      16       1.7%
20-50%      28       3.0%
50-100%     112      12.1%    â† Apenas 12% bem detectadas
```

**InterpretaÃ§Ã£o**: O modelo sÃ³ consegue detectar com confianÃ§a ~12% das falhas.

---

## âš ï¸ Problemas Identificados

### 1. **Overfitting Severo** ğŸ”´ CRÃTICO

**EvidÃªncia**:
- Train AUPRC: 0.98 vs Test AUPRC: 0.05 (95% degradaÃ§Ã£o)
- Train Recall: 99% vs Test Recall: 12% (88% degradaÃ§Ã£o)
- Val AUPRC: 0.66 vs Test AUPRC: 0.05 (92% degradaÃ§Ã£o)

**Causa Raiz**:
- Modelo com 235k parÃ¢metros Ã© muito complexo para dataset com apenas 1,654 falhas
- Label smoothing (0.01) Ã© muito baixo
- Dropout (0.3) insuficiente
- Early stopping muito permissivo (patience=15)

### 2. **DistribuiÃ§Ã£o Train/Val vs Test IncompatÃ­vel** ğŸ”´ CRÃTICO

**EvidÃªncia**:
- Taxa de falha train: 2.60% vs test: 3.20% (+23%)
- Val AUPRC Ã³timo (0.66) mas test AUPRC terrÃ­vel (0.05)
- Mesmo TC (MCA-3035541) aparece em top 1 (Pass) e bottom 1 (Fail)

**HipÃ³tese**:
- Split train/val/test pode estar **vazando informaÃ§Ã£o** (mesmo Build_ID em conjuntos diferentes?)
- Ou test set tem **distribuiÃ§Ã£o temporal diferente** (builds mais recentes = padrÃµes diferentes)

### 3. **Modelo Prioriza Passes, NÃ£o Falhas** ğŸ”´ CRÃTICO

**EvidÃªncia**:
- Top 20 ranqueados: 0 falhas
- Modelo atribui prob > 0.99 para muitos passes
- Apenas 4.3% das falhas nos top 1% dos testes

**Causa**:
- Pos_weight=5.0 Ã© **insuficiente** para imbalance ratio de 37:1
- Sampler (30% positive) pode estar causando overfitting aos positivos do train set

### 4. **Lack of Generalization** ğŸŸ¡ ALTO

**EvidÃªncia**:
- 81% das falhas tÃªm prob < 0.05
- Discrimination ratio apenas 1.84x

**Causa**:
- Features podem nÃ£o estar capturando padrÃµes generalizÃ¡veis
- SBERT embeddings (128D) podem estar perdendo informaÃ§Ã£o semÃ¢ntica crucial
- Commit parsing pode nÃ£o extrair features discriminativas

---

## ğŸ”§ RecomendaÃ§Ãµes de Melhoria

### Prioridade ALTA ğŸ”´

#### 1. Verificar Data Leakage

**AÃ§Ã£o**:
```python
# Verificar se mesmo Build_ID aparece em train/val/test
train_builds = set(df_train['Build_ID'].unique())
val_builds = set(df_val['Build_ID'].unique())
test_builds = set(df_test['Build_ID'].unique())

print(f"Train âˆ© Val: {len(train_builds & val_builds)}")
print(f"Train âˆ© Test: {len(train_builds & test_builds)}")
print(f"Val âˆ© Test: {len(val_builds & test_builds)}")
```

**Expectativa**: Deve ser 0 em todos os casos. Se nÃ£o for, **refazer split por Build_ID**.

#### 2. Reduzir Complexidade do Modelo

**ConfiguraÃ§Ã£o Atual**:
```python
model_hidden_dims: [512, 256, 128]  # 235k parÃ¢metros
```

**SugestÃ£o**:
```python
model_hidden_dims: [256, 128]  # ~60k parÃ¢metros (75% reduÃ§Ã£o)
# ou
model_hidden_dims: [128, 64]   # ~18k parÃ¢metros (92% reduÃ§Ã£o)
```

**Justificativa**: Apenas 1,654 falhas para treinar â†’ modelo menor generaliza melhor.

#### 3. Aumentar RegularizaÃ§Ã£o

**ConfiguraÃ§Ã£o Atual**:
```python
dropout: 0.3
label_smoothing: 0.01
weight_decay: 0.01
```

**SugestÃ£o**:
```python
dropout: 0.5                # +67%
label_smoothing: 0.05       # +400%
weight_decay: 0.05          # +400%
```

**Adicionar**: L1/L2 regularization adicional

#### 4. Ajustar Class Imbalance Handling

**ConfiguraÃ§Ã£o Atual**:
```python
pos_weight: 5.0
sampler_positive_fraction: 0.3
```

**SugestÃ£o**:
```python
pos_weight: 10.0  # Mais prÃ³ximo do imbalance ratio real (37:1)
sampler_positive_fraction: 0.2  # Reduzir para evitar overfitting
```

**Alternativa**: Usar Focal Loss ao invÃ©s de BCE Loss.

#### 5. Early Stopping Mais Agressivo

**ConfiguraÃ§Ã£o Atual**:
```python
patience: 15
```

**SugestÃ£o**:
```python
patience: 5
# E monitorar val_loss ao invÃ©s de val_auprc
```

**Justificativa**: Val AUPRC continuou melhorando (overfitting), mas provavelmente val_loss jÃ¡ estava degradando.

### Prioridade MÃ‰DIA ğŸŸ¡

#### 6. Aumentar DimensÃ£o SBERT

**ConfiguraÃ§Ã£o Atual**:
```python
sbert_target_dim: 128  # PCA de 384D â†’ 128D
```

**SugestÃ£o**:
```python
sbert_target_dim: 256  # Ou atÃ© 384 (sem PCA)
```

**Justificativa**: Perda de informaÃ§Ã£o semÃ¢ntica pode estar prejudicando generalizaÃ§Ã£o.

#### 7. Feature Engineering Adicional

**Adicionar**:
- Features temporais (dia da semana, hora, intervalo desde Ãºltimo build)
- Features de histÃ³rico (taxa de falha do TC nos Ãºltimos N builds)
- Features de co-ocorrÃªncia (quais TCs falham juntos)

#### 8. Ensemble / Cross-Validation

**EstratÃ©gia**:
- K-Fold Cross-Validation (k=5) por Build_ID
- Ensemble de 3-5 modelos
- Averaging de probabilidades

### Prioridade BAIXA ğŸŸ¢

#### 9. Explorar Outras Arquiteturas

- Transformers ao invÃ©s de MLP
- Graph Neural Networks (relacionamentos entre TCs)
- Gradient Boosting (XGBoost/LightGBM) ao invÃ©s de Deep Learning

#### 10. Data Augmentation

- Synthetic minority oversampling (SMOTE) no espaÃ§o de features
- Mixup/Cutmix para embeddings

---

## ğŸ“Š ComparaÃ§Ã£o: Smoke Test vs Full Test

| MÃ©trica | Smoke Test (exec_003) | Full Test (exec_005) | MudanÃ§a |
|---------|----------------------|---------------------|---------|
| **Train samples** | 3,596 | 63,532 | +1,666% |
| **Test samples** | 1,382 | 28,859 | +1,988% |
| **Train failures** | 128 (3.56%) | 1,654 (2.60%) | +1,192% |
| **Test failures** | 52 (3.76%) | 924 (3.20%) | +1,677% |
| **APFD** | 0.5033 | 0.5733 | +13.9% âœ… |
| **AUPRC** | 0.0481 | 0.0483 | +0.4% âš ï¸ |
| **Precision** | 0.0000 | 0.0702 | +âˆ âœ… |
| **Recall** | 0.0000 | 0.1212 | +âˆ âœ… |
| **Discrimination** | 1.12x | 1.84x | +64% âœ… |
| **Val AUPRC** | 0.8238 | 0.6619 | -19.7% âŒ |

**AnÃ¡lise**:
- âœ… **APFD melhorou** de 0.50 para 0.57 (+14%) - Mais dados ajudaram
- âš ï¸ **AUPRC estagnou** em ~0.048 - Sem melhoria real
- âŒ **Val AUPRC piorou** de 0.82 para 0.66 - Overfitting aumentou
- âœ… **Discrimination melhorou** de 1.12x para 1.84x - Mais dados ajudaram

**ConclusÃ£o**: Mais dados ajudaram parcialmente (APFD, discrimination), mas **overfitting piorou** (val AUPRC degradou).

---

## ğŸ¯ PrÃ³ximos Passos (Plano de AÃ§Ã£o)

### Fase 1: InvestigaÃ§Ã£o (1-2 dias)

1. âœ… **Verificar data leakage** - Analisar splits train/val/test
2. âœ… **AnÃ¡lise exploratÃ³ria** - DistribuiÃ§Ã£o de features entre train/val/test
3. âœ… **Verificar Build_ID** - DistribuiÃ§Ã£o temporal, caracterÃ­sticas

### Fase 2: Experimentos (3-5 dias)

**Experiment 006**: Data Leakage Fix (se necessÃ¡rio)
```python
# Garantir split por Build_ID, nÃ£o por amostra
```

**Experiment 007**: Reduced Complexity
```python
model_hidden_dims: [256, 128]
dropout: 0.5
label_smoothing: 0.05
patience: 5
```

**Experiment 008**: Stronger Regularization
```python
pos_weight: 10.0
sampler_positive_fraction: 0.2
weight_decay: 0.05
```

**Experiment 009**: No PCA
```python
sbert_target_dim: 384  # Usar embeddings full
```

**Experiment 010**: Ensemble
```python
# Cross-validation k=5
# Ensemble de 3 modelos
```

### Fase 3: AvaliaÃ§Ã£o (1 dia)

- Comparar resultados dos experiments 006-010
- Selecionar melhor configuraÃ§Ã£o
- Executar full test final
- Validar se APFD â‰¥ 0.70

---

## ğŸ“‹ ConclusÃ£o Final

### Status: âŒ **NÃƒO ATINGIU TARGETS**

O sistema Filo-Priori V5 completou a execuÃ§Ã£o com sucesso tÃ©cnico, mas as **mÃ©tricas de performance ficaram significativamente abaixo do esperado**:

**Problemas Principais**:
1. ğŸ”´ **Overfitting severo** (val AUPRC 0.66 â†’ test AUPRC 0.05)
2. ğŸ”´ **Data leakage suspeito** (val Ã³timo, test terrÃ­vel)
3. ğŸ”´ **Modelo prioriza passes** (top 20 = 0 falhas)
4. ğŸŸ¡ **GeneralizaÃ§Ã£o fraca** (81% falhas nÃ£o detectadas)

**Root Causes**:
- Modelo muito complexo (235k params) para poucos positivos (1,654)
- RegularizaÃ§Ã£o insuficiente (dropout 0.3, label_smoothing 0.01)
- PossÃ­vel incompatibilidade de distribuiÃ§Ã£o train/val vs test
- Pos_weight (5.0) inadequado para imbalance (37:1)

**PrÃ³ximos Passos CrÃ­ticos**:
1. âœ… Verificar data leakage (prioridade mÃ¡xima)
2. âœ… Reduzir complexidade do modelo (256/128 ao invÃ©s de 512/256/128)
3. âœ… Aumentar regularizaÃ§Ã£o (dropout 0.5, label_smoothing 0.05)
4. âœ… Ajustar pos_weight para 10.0
5. âœ… Early stopping mais agressivo (patience=5)

**Estimativa de Melhoria**: Com as correÃ§Ãµes acima, espera-se atingir:
- APFD: 0.65-0.75 (target: â‰¥ 0.70) âœ…
- AUPRC: 0.15-0.30 (target: â‰¥ 0.20) âœ…

**Tempo Estimado**: 3-5 dias para implementar e testar correÃ§Ãµes.

---

**RelatÃ³rio gerado por**: Claude Code - Filo-Priori V5 Analysis Team
**Data**: 2025-10-15
**VersÃ£o**: 1.0
